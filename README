Small collection of programs to measure disk IO performance.

These scripts have been written just for internal use, and are more
a yard than a well-finished work. Browse them at your own risk :)

CONTENT

There is a bash script for each type of test, plus some utilities.
To execute each script, it is better to first cd to the dir that contains it.
Here is the list of the directories and of the stuff they contain:
agg_thr-with-greedy_rw: aggthr-with-greedy_rw.sh
	Measures the aggregated throughput with parallel, greedy (i.e.,
	continuously issuing disk requests readers and/or writers. Both
	readers and writers are implemented with fio, and may be sequential
	or random.
	Files are read from and written to the /tmp/test directory (created
	if non existing).
	This type of workload is also used as background in the other tests.
	At the end of the test, the min, max, avg, std deviation,
	confidence interval of the read/write/total aggregated throughput
	values sampled during the run is reported.
comm_startup_lat: comm_startup_lat.sh
	Measures the cold-cache startup latency of the given command,
	launched while the same configurable workload used in the agg_thr
	test is running. At the end of the test reports min, max, avg, std
	dev and conf interval of both the sampled latencies and the read/
	write/total aggregated throughput.
video_playing_vs_commands: video_playing_vs_commands.sh
	Measures the number of frames dropped while playing a video clip and,
	at the same time, 1) repeatedly invoking a short command and 2) serving
	one of the workloads of the of the agg_thr test.
video_streaming
	This is a small package, made of a few scripts, programs and patches
	for setting up a simple experiment with a video server.
	In particular, a patched version of vlc is used, which also logs the
	frame-loss rate. This information is used by the scripts to execute
	the following experiment: measure the maximum number of movies that
	can be streamed in parallel without exceeding 1% frame loss rate. In
	brief, the steps are: start streaming a new movie, in parallel
	with the ones already being streamed, every N seconds; stop if 1%
	frame-loss rate has been reached. To perturbe the streaming, several
	intermittent file readers are run in parallel too. More details
	and instructions in the README within the package.
kern_compil_tasks-vs-rw: task_vs_rw.sh
	Measures the progress of a make, git checkout or git merge task,
	executed while the same configurable workload used in the agg_thr
	test is running. At the end of the test reports the number of lines
	written to stdout by make, or the progress of the file checkout
	phase of git merge or git checkout, plus the same statistics on disk
	throughput as the other tests.
	This script currently plays with 2.6.30, 2.6.32 and 2.6.33. You must
	provide a git tree containing at least these three versions.
	WARNING: the make test overwrites .config, whereas the other two tests
	create new branches.
fairness: fairness.sh
	Measures how the disk bandwidth is distributed among parallel
	sequential readers. This is more a work in progress than the other
	scripts.
interleaved_io: interleaved_io.sh
	Measures the aggregate throughput against an I/O pattern with
	interleaved readers. The script will spawn the desired number of
	parallel processes, each reading sequentially a 16KB-zone of the disk.
	The zones are interleaved, in that the zone read by the first process
	is contiguous to the zone read by the second process, and so on.
	At the end of the test, the min, max, avg, std deviation,
	confidence interval of the read/write/total aggregated throughput
	values sampled during the run is reported.
	By default, the script won't create any file, but read directly
	from the device on which the root directory is mounted.

run_multiple_tests
	Scripts to execute subsets of the above tests. For example,
	there is the script run_all_tests_1.sh, which repeatedly
	executes all the tests, apart from the video playing/streaming ones,
	with several workloads. It can be configured
	only by changing its code (you may want to change the number of
	repetitions of each test, the schedulers used, ...)
config_params-utilities: several files here
	. config_params.sh
		(Hopefully all and only the) parameters that need to be set
		to let the test scripts run smoothly on your system
	. lib_utils.sh
		Common functions used by the test scripts
	. calc_avg_and_co.sh
		Support script used by the other scripts to compute stats
	. calc_overall_stats.sh
		Takes as input a directory and searches, in this directory
		and in all its subdirs, all the files named as
		any of the result files produced by the
		agg_thr-with-greedy_rw.sh, comm_startup_lat.sh or task_vs_rw.sh
		scripts (fairness.sh is still a work in progress and for the
		moment its output files are not parsed by
		calc_overall_stats.sh).
		Considers any set of files with the same name as the result
		files produced in a set of repetitions of the same test,
		and computes min/max/avg/std_dev/confidence_interval
		statistics on any of the avg values reported in these files
		(hence it computes statistics over multiple repetitions of
		the same test).

USAGE AND OUTPUT OF THE SCRIPTS

The steps should be:

1) edit config_params-utilities/config_params.sh to fit your system

2) run each test manually or run multiple tests automatically through a script
   like run_multiple_tests/run_all_tests_1.sh. Each test script produces a
   result file that contains statistics on the quantities of interest
   (throughput, latency, number of lines produced by make, ...).

3) if you repeat a test more than once and store the result files in a
   given directory or in its subdirs, then you may use
   config_params-utilities/calc_overall_stats.sh to further aggregate the
   results and compute statistics on the avg values across the repetitions.

For examples and brief help just invoke the desired script with the
-h option (apart from the scripts in run_multiple_tests, which provide no help).
